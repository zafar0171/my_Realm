{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zafar0171/my_Realm/blob/main/BartRedfined.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EMlEUYiQPiG",
        "outputId": "122a5e06-fba9-43c5-a4d5-57b43fd4ca4c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiSGzzYyGHcT",
        "outputId": "6d1c5e97-7781-46db-9464-baa325d5e7f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.22.0\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (0.3.3)\n",
            "Collecting diffusers\n",
            "  Downloading diffusers-0.20.2.tar.gz (989 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m989.1/989.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (6.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.16.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.23.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.3.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (23.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.16.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2023.7.22)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.20.2-py3-none-any.whl size=1342633 sha256=c7e7147bff25a28abfb46efa61635fc65de27e497bd15c9227acd1188ac9ed08\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/8b/d9/34f7a1936109e05e9bba0cc2241a6f8cd89e25959dc7aae942\n",
            "Successfully built diffusers\n",
            "Installing collected packages: diffusers\n",
            "Successfully installed diffusers-0.20.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install accelerate\n",
        "!pip install safetensors\n",
        "!pip install diffusers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "CrXbiFZ_G7mH",
        "outputId": "31d1706c-1412-4e6b-e178-57447ff95d42"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a7d6cff0-4379-4a52-abe6-c850a8b2c6b6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a7d6cff0-4379-4a52-abe6-c850a8b2c6b6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving David Wolfe, Superfoods - The Food and Medicine of the Future (2009).pdf to David Wolfe, Superfoods - The Food and Medicine of the Future (2009).pdf\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "#pdf_name = list(uploaded.keys())[0]  # This assumes you've uploaded only one file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mxA1LYh3HS7q"
      },
      "outputs": [],
      "source": [
        "pdf_name = list(uploaded.keys())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikqoAadvHSJm",
        "outputId": "bf51c995-c4d7-4492-9978-f3ffd611e1f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (3.2.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (41.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
            "Installing collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20221105\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfminer.six\n",
        "\n",
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "def extract_text_from_pdf(pdf_name):\n",
        "    return extract_text(pdf_name)\n",
        "\n",
        "book_text = extract_text_from_pdf(pdf_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nIKLWqEXJQe8"
      },
      "outputs": [],
      "source": [
        "def is_potential_heading(line):\n",
        "    \"\"\"Determine if a line is a potential heading based on its length and capitalization.\"\"\"\n",
        "    # Check if line is short\n",
        "    if len(line.split()) < 6:\n",
        "        # Check if majority of the words are capitalized\n",
        "        capitalized_words = sum(1 for word in line.split() if word.istitle())\n",
        "        if capitalized_words / len(line.split()) > 0.5:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "sections = []\n",
        "current_section = []\n",
        "\n",
        "lines = [line.strip() for line in book_text.split('\\n') if line.strip()]\n",
        "i = 0\n",
        "\n",
        "while i < len(lines):\n",
        "    line = lines[i]\n",
        "    if is_potential_heading(line):\n",
        "        # If we've been collecting a section, add it to sections\n",
        "        if current_section:\n",
        "            sections.append('\\n'.join(current_section))\n",
        "            current_section = []\n",
        "        # Add the heading to the current section and move to the next line\n",
        "        current_section.append(line)\n",
        "        i += 1\n",
        "    else:\n",
        "        # Add lines to the current section until another potential heading or the end of the document\n",
        "        while i < len(lines) and not is_potential_heading(lines[i]):\n",
        "            current_section.append(lines[i])\n",
        "            i += 1\n",
        "\n",
        "# Add the last section, if any remains\n",
        "if current_section:\n",
        "    sections.append('\\n'.join(current_section))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "7CvMYJexJ-Hm"
      },
      "outputs": [],
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "def generate_initial_summaries(sections):\n",
        "    model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "    tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "    subset_sections = sections[10:20]\n",
        "    #summaries = generate_initial_summaries(subset_sections)\n",
        " m\n",
        "    summaries3 = []\n",
        "    for section in sections[700:800]:\n",
        "        inputs = tokenizer([section], max_length=1024, return_tensors='pt', truncation=True)\n",
        "        summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=30, max_length=150, early_stopping=True)\n",
        "        summaries3.append(tokenizer.decode(summary_ids[0], skip_special_tokens=True))\n",
        "\n",
        "    return summaries3\n",
        "\n",
        "summaries3 = generate_initial_summaries(sections)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "# Write summaries to a file\n",
        "with open('summaries2.txt', 'w') as f:\n",
        "    for summary in summaries1:\n",
        "        f.write(\"%s\\n\" % summary)\n",
        "\n",
        "# Download the file to your local system\n",
        "files.download('summaries2.txt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "q8EEeTBNS42t",
        "outputId": "7b00f07e-9dc6-4584-9fe6-de090d26dfe0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_32ec5cc2-dbf8-4e0d-b20a-7e627129f977\", \"summaries2.txt\", 30884)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('summaries1.txt', 'w') as f:\n",
        "    for summary in summaries1:\n",
        "        f.write(\"%s\\n\" % summary)\n"
      ],
      "metadata": {
        "id": "0Z0csZKwnl1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('summaries1.json', 'w') as f:\n",
        "    json.dump(summaries1, f)\n"
      ],
      "metadata": {
        "id": "EqyorC3Yn1Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('summaries.txt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "471QpHoToBYO",
        "outputId": "e031b7eb-c4f1-483f-def4-71be58e3f0d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_63b3d1ab-f08e-4ddb-8148-d9876cad29e5\", \"summaries.txt\", 88091)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('summaries.json')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "e91cq4nVoGwO",
        "outputId": "47ec9cbe-4647-4021-f181-605aaed74dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f004ccb0-7750-4741-add9-92430ecb4005\", \"summaries.json\", 93575)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_sections = sections[50:100]  # Python indexing is exclusive at the end\n"
      ],
      "metadata": {
        "id": "9xaRRF7lq0qr"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "4c1vSg9EwwPY",
        "outputId": "af5eeb06-9dcb-491d-efa6-69b28a5b1545"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4862c0b5-d805-4a47-8802-b40becb54fbb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4862c0b5-d805-4a47-8802-b40becb54fbb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving summaries.txt to summaries.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('summaries.txt', 'r') as f:\n",
        "    summaries = f.readlines()\n"
      ],
      "metadata": {
        "id": "Nvk_IKVotNP1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(summaries[50:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoNB4z2o7rHh",
        "outputId": "6d4d878d-d3b3-48e6-b36f-7445ad5af37c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sections[100:250]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGLgIeaH7wfC",
        "outputId": "2850290f-ffb7-4ea0-8cd6-8ee82b870ca4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Goji Berries',\n",
              " 'Fountain of Youth',\n",
              " 'Latin Names:\\nMajor Asian varieties: Lycium barbarum, Lycium chinensis\\nMajor  American  varieties:  Lycium  andersonii,  Lycium  berlandieri,  Lycium\\nbrevipes, Lycium californicum, Lycium carolinianum, Lycium cooperi, Lycium\\nexsertum,  Lycium  fremontii,  Lycium  halimifolium,  Lycium  macrodon,  Lycium\\npallidum,  Lycium  parishii,  Lycium  puberlum,  Lycium  torreyi  (Lycium  is  also\\nspelled Lyceum, depending on the reference text or web site)',\n",
              " 'Common Names:\\nGoji Berry, Wolfberry, Boxthorn, Matrimony Vine, Desert Thorn',\n",
              " 'Superfood Type:\\nBerry (fruit)\\nThe  following  parts  of  the  goji  berry  bush  have  also  been  used  in  herbal\\npreparations or as food:',\n",
              " 'Seeds',\n",
              " 'Flowers',\n",
              " 'Leaves',\n",
              " 'Roots',\n",
              " 'History, Facts, and Legends\\nGoji berries grow on a bush that develops like a vine when grown in the shade. At\\nthe very largest, the goji bush will grow six feet tall and will have a radius of around\\nthree feet. The ovate leaves range in length from half an inch to four inches depending\\non  location  and  variety.  Red  striations  are  sometimes  seen  in  the  bark  of  the  plant.\\nAlthough  not  specifically  a  thorny  plant  like  a  rose,  some  American  goji  berry\\nvarieties  can  develop  some  thornlike  stems.  During  the  nonflowering  seasons\\n(summer,  fall,  and  winter),  the  goji  berry  bush  may  lose  some  or  all  of  its  leaves,\\nwhich  makes  it  more  difficult  to  recognize.  In  spring,  however,  the  leaves  fill  out\\nbeautifully  and  pale-white  to  purple  flowers  enrich  the  plant,  usually  beginning  in\\nMarch in the northern hemisphere. Following the flower pollination, fruit berries will\\nsoon follow. Goji berries range in color from pale yellow to dark sunfire orange to\\ndeep  red.  Sometimes  the  raisin-sized  goji  berries  are  oblong,  like  footballs.  I  have\\neven  seen  goji  berries  that  are  shaped  like  small  peppers.  Often  the  berries  are\\nentirely spherical.\\nThere are an estimated eighty-five species of goji berry in Asia and fifteen species\\nin North and Central America. It is possible, based on this geographic dispersion, that\\nthe  goji  berry  was  brought  to  North  America  by  groups  who  migrated  from  Asia,\\neither by boat or across the Bering Land Bridge.\\nThe  goji  berries  of Asia  and America  are  remarkably  similar.  The  history  of  the\\nAsian varieties is better documented, researched, and consecrated in legend and lore,\\nbut both the Asian and American goji berry varieties deserve special attention because\\ntheir histories and health-giving properties are so rich.\\nAll goji berries that I have studied and grown are remarkably adaptable. The goji\\nberries  grow  as  wonderfully  in  harsh,  dry  deserts  as  they  do  in  the  tropics.  Goji\\nberries  also  tolerate  freezing  winters  and  have  been  recorded  to  grow  well  in  such\\nplaces  as  Nova  Scotia  and  British  Columbia.  Perhaps  most  interesting  is  that  goji\\nberries can handle daily swings in temperature as great as 40 degrees Fahrenheit.\\nThe  goji  berry  was  categorized  under  the  Linnaean  Latin  categorization  system\\nunder  the  genus Lycium  (or Lyceum).  From  its  Greek  root,  the  word Lyceum  means\\n“school of learning.” And that is what the masters of Chinese herbalism believed the\\ngoji  berry  could  provide.  Legend  has  it  that  one  can  tune  into  a  pharmacopeia  of\\nherbal  data  contained  within  the  plant  simply  by  eating  goji  berries.  Further,  some\\nbelieve that if one studies, grows, and eats the goji berry, it is able to teach you the\\nfundamental principles of Chinese herbalism.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_sections = sections[100:300]"
      ],
      "metadata": {
        "id": "Sy_cm4x89jqw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer\n",
        "\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "# Assuming `summaries` is a list of manually created summaries\n",
        "def tokenize_data(sections, summaries, tokenizer, max_length=1024, max_summary_length=150):\n",
        "    inputs = tokenizer(sections, truncation=True, padding='max_length', max_length=max_length, return_tensors='pt')\n",
        "    targets = tokenizer(summaries, truncation=True, padding='max_length', max_length=max_summary_length, return_tensors='pt')\n",
        "    return inputs, targets\n",
        "\n",
        "inputs, targets = tokenize_data(selected_sections, summaries[50:250], tokenizer)\n"
      ],
      "metadata": {
        "id": "kUg-dDsMoi8B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "b65047c9f68f45fc9ea91c9dea68d490",
            "b2717392febe427bbf1880a9d2badbd4",
            "41eb481a6cd448c89e04a2d9f0b3be4b",
            "81090e04fa544b08b3ed5dfbdd541262",
            "5c311aa643da47138f75756f10517a66",
            "e0861831f8f74515800d7f689634ec53",
            "1d854f248fa04b8cae9ed2456a865820",
            "df04483e138c4897a454e32739ee7e75",
            "6590f696a34b43ebad6dec4c825a6407",
            "190373a948fe4dd189add2595c43df8e",
            "8a2e353ad1aa44f493a7e362994723a1",
            "38434f784ef44a939a9083b326a57286",
            "e73eb7bb7ef241dc8d1a5f3d1bdb4c49",
            "77def51c336d42149bd3620887a98ea1",
            "f3875c84581744cfb2999906e20a5636",
            "55b16c02d9684446b7620e02785c6c64",
            "42a82287037240c0b9120e4e8e0812ae",
            "6686e9ac68064caa9176408259a6ccc0",
            "c794f2d5bf524ecf9ab67aecf692a691",
            "494bc067beca4b2082d61e5fdd970f71",
            "9c815a646dcc4b519cf267ee21418152",
            "3245a303502546cfa6890fd7c52b2a8f",
            "6c68df0f2e294b62a9edc555132bc948",
            "48fffd306355434bbafe681ca447d0ae",
            "f39c2a613d2f4cd8a0e18fe052b02f98",
            "541e558654df4097bf71119302bc03c0",
            "4728e2264a3d4f93b143dbead7285216",
            "dc611585e8d644fc89055b92ccfdc9d6",
            "3b6236b2330e442db5f3187d37f2ab22",
            "842345bd8721411cbf4ebb4cafd3c8e9",
            "f7266f48f1944df08243c2b76742aa26",
            "24d3edd92b794424bb4d15646668fdf0",
            "9f1ca9eae8ca44828d2e7540b907400c"
          ]
        },
        "outputId": "02ba635b-4db4-4324-f5c5-fe64d8895d7a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b65047c9f68f45fc9ea91c9dea68d490"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38434f784ef44a939a9083b326a57286"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c68df0f2e294b62a9edc555132bc948"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_sections = sections[50:100]"
      ],
      "metadata": {
        "id": "llzYUXm0F4Jk"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_sections_eval = sections[300:400]"
      ],
      "metadata": {
        "id": "xOoq0AoTvFpY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(selected_sections))\n",
        "print(len(selected_sections_eval))\n",
        "print(len(summaries[50:250]))\n",
        "print(len(summaries[250:350]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liiBInuh-8IG",
        "outputId": "6361a583-d664-450e-bc6f-a21c8a1895fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "100\n",
            "200\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summaries"
      ],
      "metadata": {
        "id": "o_pOC8jBvRAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the evaluation data\n",
        "eval_inputs, eval_targets = tokenize_data(selected_sections_eval, summaries[250:350], tokenizer)"
      ],
      "metadata": {
        "id": "Nn7VNWH8u9RY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "bLxZx4-7wu7W"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, TrainingArguments, Trainer\n",
        "\n",
        "# Load pre-trained BART model\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='C:\\\\Users\\\\modza\\\\Downloads\\\\BartModelData',\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=2,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    save_steps=100,\n",
        "    save_total_limit=2,\n",
        "    evaluation_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "# Tokenize the evaluation data\n",
        "eval_inputs, eval_targets = tokenize_data(selected_sections_eval, summaries[150:200], tokenizer)\n",
        "\n",
        "# Create a dataset class\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, inputs, targets):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_data = {key: val[idx] for key, val in self.inputs.items()}\n",
        "        target_data = {key: val[idx] for key, val in self.targets.items()}\n",
        "        return {\"input_ids\": input_data[\"input_ids\"], \"attention_mask\": input_data[\"attention_mask\"], \"labels\": target_data[\"input_ids\"]}\n",
        "\n",
        "# Assuming 'inputs' and 'targets' are already defined for the training data\n",
        "train_dataset = CustomDataset(inputs, targets)\n",
        "\n",
        "# Create the evaluation dataset\n",
        "eval_dataset = CustomDataset(eval_inputs, eval_targets)\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515,
          "referenced_widgets": [
            "c6370fde738b4596b3d437ee6e65104f",
            "981ede54163e4f68a24d9a8724e7e2fd",
            "3ae658b56c654d70be2252cf8d23da17",
            "61f60d5d50ed4778a79dad870bee629f",
            "f5ccb072631c476d84aab5229f1969bd",
            "d6c0566ac5f749d59eb6d5ef10d303a1",
            "16382b23b4814b868973f683392db3da",
            "f79be3b745174644b480d99a816961b1",
            "fb91ed0fbdbf4ba18108e60fd77f1365",
            "46c87a3e2ea446f8bffa56e6d7de723e",
            "977733955da547e8b576e1b3de5a94ef",
            "d8c0edb5e720462c83460f696721753f",
            "03e3df919dc14ecda67b078a5a59eaa2",
            "dacd70cfe5ca402baade375f8029b192",
            "8c408cc2b35b49ebaf619b97d9d7193c",
            "db26e957c7d84408bf0f00d3cb25aa9d",
            "7ce916e72f2645e5825d8b91eab7704d",
            "504f7a4390b84ff4a242cb42408ba7fd",
            "d5c55170e3fd4dfea25eea31bd307176",
            "39f1fa54bac145619d802f37c40547c9",
            "493ea7e5494a40ab87a203f6db40fed4",
            "cfe47271d1e94d4fbca9ca733dd4e1b7"
          ]
        },
        "id": "Z9lRmg5uwt94",
        "outputId": "8d5b4609-b7d9-4a14-9b7c-d53cd17e83b5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6370fde738b4596b3d437ee6e65104f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8c0edb5e720462c83460f696721753f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='51' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 51/100 01:25 < 01:25, 0.57 it/s, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 5/13 00:04 < 00:09, 0.81 it/s]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-bf9183ce8417>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1556\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1943\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1944\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2254\u001b[0m                     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2255\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2256\u001b[0;31m                 \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2257\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2972\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   2973\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3149\u001b[0m         \u001b[0mobserved_num_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3150\u001b[0m         \u001b[0;31m# Main evaluation loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3151\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3152\u001b[0m             \u001b[0;31m# Update the observed num examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3153\u001b[0m             \u001b[0mobserved_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                     \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mnext_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mcurrent_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-bf9183ce8417>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mtarget_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-bf9183ce8417>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mtarget_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 50 is out of bounds for dimension 0 with size 50"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(selected_sections))\n",
        "print(len(selected_sections_eval))\n",
        "print(len(summaries[50:250]))\n",
        "print(len(summaries[250:350]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8Xg9s6z6spo",
        "outputId": "eab62183-2700-491f-970a-b3d64d7b4a24"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "100\n",
            "200\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_data(sections, summaries, tokenizer):\n",
        "    inputs = tokenizer(sections, truncation=True, padding='max_length', max_length=1024, return_tensors='pt')\n",
        "    targets = tokenizer(summaries, truncation=True, padding='max_length', max_length=150, return_tensors='pt')\n",
        "    return inputs, targets\n",
        "\n",
        "train_inputs, train_targets = tokenize_data(selected_sections, summaries[50:250], tokenizer)\n",
        "eval_inputs, eval_targets = tokenize_data(selected_sections_eval, summaries[250:350], tokenizer)\n"
      ],
      "metadata": {
        "id": "s-3xS9d97U0I"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_inputs[\"input_ids\"].shape)\n",
        "print(train_targets[\"input_ids\"].shape)\n",
        "print(eval_inputs[\"input_ids\"].shape)\n",
        "print(eval_targets[\"input_ids\"].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pua1WZ9T7AAK",
        "outputId": "e3b52731-5a25-4539-8160-d620107f0314"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([200, 1024])\n",
            "torch.Size([200, 150])\n",
            "torch.Size([100, 1024])\n",
            "torch.Size([100, 150])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, TrainingArguments, Trainer\n",
        "\n",
        "# Load pre-trained BART model\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=2,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    save_steps=100,\n",
        "    save_total_limit=2,\n",
        "    evaluation_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "# Create a dataset class\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, inputs, targets):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_data = {key: val[idx] for key, val in self.inputs.items()}\n",
        "        target_data = {key: val[idx] for key, val in self.targets.items()}\n",
        "        return {\n",
        "            \"input_ids\": input_data[\"input_ids\"],\n",
        "            \"attention_mask\": input_data[\"attention_mask\"],\n",
        "            \"labels\": target_data[\"input_ids\"]\n",
        "        }\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=CustomDataset(train_inputs, train_targets),\n",
        "    eval_dataset=CustomDataset(eval_inputs, eval_targets)\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "mp-aywp_7q5r",
        "outputId": "0d3c95cd-ffb0-4a18-a4de-acc83163817e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 03:44, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.345300</td>\n",
              "      <td>0.263054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.127800</td>\n",
              "      <td>0.219378</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=100, training_loss=0.7784451496601105, metrics={'train_runtime': 226.5748, 'train_samples_per_second': 1.765, 'train_steps_per_second': 0.441, 'total_flos': 866841840844800.0, 'train_loss': 0.7784451496601105, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(text, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Generates a summary for the provided text using the given model and tokenizer.\n",
        "\n",
        "    Args:\n",
        "    - text (str): The article or text to be summarized.\n",
        "    - model (BartForConditionalGeneration): The trained BART model.\n",
        "    - tokenizer (BartTokenizer): The tokenizer associated with the BART model.\n",
        "\n",
        "    Returns:\n",
        "    - summary (str): The generated summary.\n",
        "    \"\"\"\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
        "\n",
        "    # Generate the summary with the model\n",
        "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=30, max_length=150, early_stopping=True)\n",
        "\n",
        "    # Decode the summary ID and return the result\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "yWuExneJ8ovn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(text, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Generates a summary for the provided text using the given model and tokenizer.\n",
        "\n",
        "    Args:\n",
        "    - text (str): The article or text to be summarized.\n",
        "    - model (BartForConditionalGeneration): The trained BART model.\n",
        "    - tokenizer (BartTokenizer): The tokenizer associated with the BART model.\n",
        "\n",
        "    Returns:\n",
        "    - summary (str): The generated summary.\n",
        "    \"\"\"\n",
        "    device = model.device  # Get the device where the model is\n",
        "\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True).to(device)  # Send inputs to the same device\n",
        "\n",
        "    # Generate the summary with the model\n",
        "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=30, max_length=150, early_stopping=True)\n",
        "\n",
        "    # Decode the summary ID and return the result\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "0vQ3UFIR9VC1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "#article = \"Your lengthy article or text goes here...\"\n",
        "summary_result = generate_summary(article1, model, tokenizer)\n",
        "print(summary_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECnw6D6v8wSk",
        "outputId": "3b1fade0-0807-4d75-ef69-3203504edb4b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chia seeds are a great source of fiber, which can improve heart health, reduce cholesterol levels, and promote intestinal health. They also contain quercetin, an antioxidant that can reduce the risk of heart disease. Recent research has found that chia seeds can help promote healthy skin and support the digestive system.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "f-jPvF7y9UJg",
        "outputId": "f731684a-87ad-4842-9da3-475998de1b0a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Chia seeds are a great source of fiber, which can improve heart health, reduce cholesterol levels, and promote intestinal health.1 They also contain quercetin, an antioxidant that can reduce the risk of heart disease.0 Chia seeds are high in omega-3 fatty acids, which have anti-inflammatory and heart health properties.5 They also contain minerals such as calcium, magnesium, and phosphorus, which are beneficial for bone health.2 Additionally, chia seeds provide numerous B-vitamins, including thiamin, riboflavin, and niacin, which play important roles in metabolism and cardiovascular health.3 Recent research has found that chia seeds can help promote healthy skin, reduce signs of aging, support the digestive system, and build stronger bones'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path where you want to save the model\n",
        "#save_path = 'C:\\\\Users\\\\modza\\\\Downloads\\\\BartModelData\\\\saved_model'\n",
        "\n",
        "save_path = './BartModelData_saved_model'\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PjJHQwh4ty4",
        "outputId": "a7ac2866-586d-47fa-b2b8-35511714681b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./BartModelData_saved_model/tokenizer_config.json',\n",
              " './BartModelData_saved_model/special_tokens_map.json',\n",
              " './BartModelData_saved_model/vocab.json',\n",
              " './BartModelData_saved_model/merges.txt',\n",
              " './BartModelData_saved_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r ./BartModelData_saved_model.zip ./BartModelData_saved_model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZOxG7OJMGqf",
        "outputId": "700ef5d2-de6c-40c2-a3d2-f872389f9e12"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: BartModelData_saved_model/ (stored 0%)\n",
            "  adding: BartModelData_saved_model/config.json (deflated 61%)\n",
            "  adding: BartModelData_saved_model/merges.txt (deflated 53%)\n",
            "  adding: BartModelData_saved_model/tokenizer_config.json (deflated 81%)\n",
            "  adding: BartModelData_saved_model/pytorch_model.bin (deflated 7%)\n",
            "  adding: BartModelData_saved_model/generation_config.json (deflated 47%)\n",
            "  adding: BartModelData_saved_model/vocab.json (deflated 68%)\n",
            "  adding: BartModelData_saved_model/special_tokens_map.json (deflated 85%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNdkjUKBWlAG",
        "outputId": "987581ba-5c94-457d-d86c-28a3f0a26763"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.10).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0QUHoGiZEXd",
        "outputId": "a5cae119-7e53-45b7-996e-2c8b2e5bafea"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
            "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
            "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
            "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
            "Initialized empty Git repository in /content/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"modzafar28@gmail.com\"\n",
        "!git config --global user.name \"zafar0171\"\n"
      ],
      "metadata": {
        "id": "hkcROCEwZKXM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add -A\n"
      ],
      "metadata": {
        "id": "BSNjXfZNWygS"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_directory = \"model\"\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wfPgn8cZOoM",
        "outputId": "09c5d8f6-2598-46ca-e548-f25739d7e4cf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('model/tokenizer_config.json',\n",
              " 'model/special_tokens_map.json',\n",
              " 'model/vocab.json',\n",
              " 'model/merges.txt',\n",
              " 'model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add -A\n",
        "!git commit -m \"Save trained BART model\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfhMy8UlZT0l",
        "outputId": "fb33b55c-07be-4907-cbfd-b93e2de87b67"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[master (root-commit) eb88c62] Save trained BART model\n",
            " 47 files changed, 252431 insertions(+)\n",
            " create mode 100644 .config/.last_opt_in_prompt.yaml\n",
            " create mode 100644 .config/.last_survey_prompt.yaml\n",
            " create mode 100644 .config/.last_update_check.json\n",
            " create mode 100644 .config/active_config\n",
            " create mode 100644 .config/config_sentinel\n",
            " create mode 100644 .config/configurations/config_default\n",
            " create mode 100644 .config/default_configs.db\n",
            " create mode 100644 .config/gce\n",
            " create mode 100644 .config/logs/2023.08.31/13.24.06.550663.log\n",
            " create mode 100644 .config/logs/2023.08.31/13.24.32.047854.log\n",
            " create mode 100644 .config/logs/2023.08.31/13.24.55.974256.log\n",
            " create mode 100644 .config/logs/2023.08.31/13.25.03.338259.log\n",
            " create mode 100644 .config/logs/2023.08.31/13.25.27.753261.log\n",
            " create mode 100644 .config/logs/2023.08.31/13.25.28.491021.log\n",
            " create mode 100644 BartModelData_saved_model.zip\n",
            " create mode 100644 BartModelData_saved_model/config.json\n",
            " create mode 100644 BartModelData_saved_model/generation_config.json\n",
            " create mode 100644 BartModelData_saved_model/merges.txt\n",
            " create mode 100644 BartModelData_saved_model/pytorch_model.bin\n",
            " create mode 100644 BartModelData_saved_model/special_tokens_map.json\n",
            " create mode 100644 BartModelData_saved_model/tokenizer_config.json\n",
            " create mode 100644 BartModelData_saved_model/vocab.json\n",
            " create mode 100644 David Wolfe, Superfoods - The Food and Medicine of the Future (2009).pdf\n",
            " create mode 100644 logs/events.out.tfevents.1693809354.7bba8a18a161.1283.0\n",
            " create mode 100644 logs/events.out.tfevents.1693809828.7bba8a18a161.1283.1\n",
            " create mode 100644 model/config.json\n",
            " create mode 100644 model/generation_config.json\n",
            " create mode 100644 model/merges.txt\n",
            " create mode 100644 model/pytorch_model.bin\n",
            " create mode 100644 model/special_tokens_map.json\n",
            " create mode 100644 model/tokenizer_config.json\n",
            " create mode 100644 model/vocab.json\n",
            " create mode 100644 results/checkpoint-100/config.json\n",
            " create mode 100644 results/checkpoint-100/generation_config.json\n",
            " create mode 100644 results/checkpoint-100/optimizer.pt\n",
            " create mode 100644 results/checkpoint-100/pytorch_model.bin\n",
            " create mode 100644 results/checkpoint-100/rng_state.pth\n",
            " create mode 100644 results/checkpoint-100/scheduler.pt\n",
            " create mode 100644 results/checkpoint-100/trainer_state.json\n",
            " create mode 100644 results/checkpoint-100/training_args.bin\n",
            " create mode 100755 sample_data/README.md\n",
            " create mode 100755 sample_data/anscombe.json\n",
            " create mode 100644 sample_data/california_housing_test.csv\n",
            " create mode 100644 sample_data/california_housing_train.csv\n",
            " create mode 100644 sample_data/mnist_test.csv\n",
            " create mode 100644 sample_data/mnist_train_small.csv\n",
            " create mode 100644 summaries.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote add origin https://zafar0171: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@github.com/Zafar0171/my_Realm.git\n"
      ],
      "metadata": {
        "id": "GDjG-BzibR2z"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote remove origin\n",
        "!git remote add origin https://zafar0171:Modassirzafar1@github.com/Zafar0171/my_Realm.git\n",
        "!git push -u origin master\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSdJzTyUbeel",
        "outputId": "527fde58-20bf-4d17-85c6-20a189d5af94"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Support for password authentication was removed on August 13, 2021.\n",
            "remote: Please see https://docs.github.com/en/get-started/getting-started-with-git/about-remote-repositories#cloning-with-https-urls for information on currently recommended modes of authentication.\n",
            "fatal: Authentication failed for 'https://github.com/Zafar0171/my_Realm.git/'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config http.postBuffer 524288000\n"
      ],
      "metadata": {
        "id": "KtCNObm3Gj9f"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git push -u origin master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYvnk8jPcDt3",
        "outputId": "d12bb4e1-1b79-429c-aee4-d97da31e18d9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 48, done.\n",
            "Counting objects:   2% (1/48)\rCounting objects:   4% (2/48)\rCounting objects:   6% (3/48)\rCounting objects:   8% (4/48)\rCounting objects:  10% (5/48)\rCounting objects:  12% (6/48)\rCounting objects:  14% (7/48)\rCounting objects:  16% (8/48)\rCounting objects:  18% (9/48)\rCounting objects:  20% (10/48)\rCounting objects:  22% (11/48)\rCounting objects:  25% (12/48)\rCounting objects:  27% (13/48)\rCounting objects:  29% (14/48)\rCounting objects:  31% (15/48)\rCounting objects:  33% (16/48)\rCounting objects:  35% (17/48)\rCounting objects:  37% (18/48)\rCounting objects:  39% (19/48)\rCounting objects:  41% (20/48)\rCounting objects:  43% (21/48)\rCounting objects:  45% (22/48)\rCounting objects:  47% (23/48)\rCounting objects:  50% (24/48)\rCounting objects:  52% (25/48)\rCounting objects:  54% (26/48)\rCounting objects:  56% (27/48)\rCounting objects:  58% (28/48)\rCounting objects:  60% (29/48)\rCounting objects:  62% (30/48)\rCounting objects:  64% (31/48)\rCounting objects:  66% (32/48)\rCounting objects:  68% (33/48)\rCounting objects:  70% (34/48)\rCounting objects:  72% (35/48)\rCounting objects:  75% (36/48)\rCounting objects:  77% (37/48)\rCounting objects:  79% (38/48)\rCounting objects:  81% (39/48)\rCounting objects:  83% (40/48)\rCounting objects:  85% (41/48)\rCounting objects:  87% (42/48)\rCounting objects:  89% (43/48)\rCounting objects:  91% (44/48)\rCounting objects:  93% (45/48)\rCounting objects:  95% (46/48)\rCounting objects:  97% (47/48)\rCounting objects: 100% (48/48)\rCounting objects: 100% (48/48), done.\n",
            "Delta compression using up to 8 threads\n",
            "Compressing objects: 100% (37/37), done.\n",
            "error: RPC failed; HTTP 500 curl 22 The requested URL returned error: 500\n",
            "send-pack: unexpected disconnect while reading sideband packet\n",
            "Writing objects: 100% (48/48), 5.59 GiB | 79.18 MiB/s, done.\n",
            "Total 48 (delta 6), reused 3 (delta 0), pack-reused 0\n",
            "fatal: the remote end hung up unexpectedly\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('./BartModelData_saved_model.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "UbfaP_47MUbi",
        "outputId": "a23d4ba7-ef99-4a25-ff12-4c2822f2799e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1f95d242-f2be-4be6-8ea6-3eefac11169a\", \"BartModelData_saved_model.zip\", 1507270164)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global http.postBuffer 157286400\n"
      ],
      "metadata": {
        "id": "arIEYpc-BupE"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path with your chosen name\n",
        "save_path = 'C:\\\\Users\\\\modza\\\\Downloads\\\\BART_CustomSummarization'\n",
        "\n",
        "# Save the model and its configuration\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n"
      ],
      "metadata": {
        "id": "R3HyGTqgpq1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0b522d6-8014-44ed-bcb3-ee292db54ecf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('C:\\\\Users\\\\modza\\\\Downloads\\\\BART_CustomSummarization/tokenizer_config.json',\n",
              " 'C:\\\\Users\\\\modza\\\\Downloads\\\\BART_CustomSummarization/special_tokens_map.json',\n",
              " 'C:\\\\Users\\\\modza\\\\Downloads\\\\BART_CustomSummarization/vocab.json',\n",
              " 'C:\\\\Users\\\\modza\\\\Downloads\\\\BART_CustomSummarization/merges.txt',\n",
              " 'C:\\\\Users\\\\modza\\\\Downloads\\\\BART_CustomSummarization/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "JyoXIevGGTOO"
      },
      "outputs": [],
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "def extract_benefits_from_summary(article):\n",
        "    # Load pre-trained BART model for summarization\n",
        "    model = BartForConditionalGeneration.from_pretrained('C:\\\\Users\\\\modza\\\\Downloads\\\\BART_CustomSummarization')\n",
        "    tokenizer = BartTokenizer.from_pretrained('C:\\\\Users\\\\modza\\\\Downloads\\\\BART_CustomSummarization')\n",
        "\n",
        "\n",
        "    # Generate summary\n",
        "    inputs = tokenizer([article], max_length=1024, return_tensors='pt', truncation=True)\n",
        "    summary_ids = model.generate(inputs['input_ids'], num_beams=6, min_length=50, max_length=300, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Define keywords or phrases that might indicate benefits\n",
        "    benefit_keywords = ['benefit', 'advantage', 'gain', 'merit','prevention','Treatment','cure','reward', 'bonus', 'profit', 'value', 'asset', 'boon', 'perk', 'upside', 'plus', 'positive', 'improvement', 'enhancement', 'dividend', 'utility', 'favor', 'help', 'aid', 'good', 'pro']\n",
        "\n",
        "    # Extract sentences containing benefits\n",
        "    benefits_sentences = [sentence for sentence in summary.split('. ') if any(keyword in sentence.lower() for keyword in benefit_keywords)]\n",
        "\n",
        "    # Combine the extracted sentences into bullet points\n",
        "    benefits_summary = '\\n'.join([f'- {sentence}' for sentence in benefits_sentences])\n",
        "\n",
        "    return benefits_summary\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "# 1. Load the trained model and tokenizer\n",
        "#model_path = 'C:\\\\Users\\\\modza\\\\Downloads\\\\BART_CustomSummarization'  # Adjust this path to where you saved your model\n",
        "#model = BartForConditionalGeneration.from_pretrained(model_path)\n",
        "#tokenizer = BartTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# 2. Tokenize the article\n",
        "article = (\"Chia seeds are a great source of fiber, which can improve heart health, reduce cholesterol levels, \"\n",
        "           \"and promote intestinal health.1 They also contain quercetin, an antioxidant that can reduce the risk \"\n",
        "           \"of heart disease.0 Chia seeds are high in omega-3 fatty acids, which have anti-inflammatory and heart \"\n",
        "           \"health properties.5 They also contain minerals such as calcium, magnesium, and phosphorus, which are \"\n",
        "           \"beneficial for bone health.2 Additionally, chia seeds provide numerous B-vitamins, including thiamin, \"\n",
        "           \"riboflavin, and niacin, which play important roles in metabolism and cardiovascular health.3 Recent research \"\n",
        "           \"has found that chia seeds can help promote healthy skin, \")\n",
        "inputs = tokenizer([article], max_length=1024, return_tensors='pt', truncation=True)\n",
        "\n",
        "# 3. Generate the summary\n",
        "summary_ids = model.generate(inputs['input_ids'], num_beams=6, min_length=30, max_length=150, early_stopping=True)\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_X0Ae6Z648S",
        "outputId": "88ab40bd-43a5-4f43-c9bd-b21af775114b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chia seeds are a great source of fiber, which can improve heart health, reduce cholesterol levels, and promote intestinal health. They also contain quercetin, an antioxidant that can reduce the risk of heart disease. Recent research has found that chia seeds can help promote healthy skin.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the summaries from your file\n",
        "#with open(\"path_to_summaries.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        " #   all_summaries = file.readlines()\n",
        "\n",
        "# List of uncertainty-inflicting words\n",
        "uncertain_words = [\n",
        "    \"might\", \"might've\", \"mightn't\",\"can\",\"will\"\n",
        "    \"could\", \"could've\", \"couldn't\",\n",
        "    \"should\", \"should've\", \"shouldn't\",\n",
        "    \"would\", \"would've\", \"wouldn't\",\n",
        "    \"may\", \"may've\", \"mayn't\",\n",
        "    \"potentially\", \"possibly\",\n",
        "    \"seems\", \"seemingly\",\n",
        "    \"appears\", \"apparently\",\n",
        "    \"believe\", \"believes\", \"believed\",\n",
        "    \"suggest\", \"suggests\", \"suggested\",\n",
        "    \"indicate\", \"indicates\", \"indicated\",\n",
        "    \"assume\", \"assumes\", \"assumed\",\n",
        "    \"presume\", \"presumes\", \"presumed\",\n",
        "    \"speculate\", \"speculates\", \"speculated\",\n",
        "    \"guess\", \"guesses\", \"guessed\",\n",
        "    \"think\", \"thinks\", \"thought\",\n",
        "    \"probably\", \"likely\", \"unlikely\",\n",
        "    \"perhaps\", \"maybe\", \"somewhat\",\n",
        "    \"oftentimes\", \"sometimes\",\n",
        "    \"usually\", \"generally\", \"typically\",\n",
        "    \"tend to\", \"tends to\",\n",
        "    \"often\", \"rarely\", \"occasionally\",\n",
        "    \"imply\", \"implies\", \"implied\",\n",
        "    \"unsure\", \"uncertain\", \"ambiguous\", \"vague\",\n",
        "    \"doubt\", \"doubts\", \"doubted\", \"doubtful\"]\n",
        "\n",
        "\n",
        "# Filter out summaries that contain uncertain words\n",
        "definitive_summaries = [summary for summary in summaries if not any(word in summary.lower() for word in uncertain_words)]\n"
      ],
      "metadata": {
        "id": "penNrSpPD9TB"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "# Read the summaries from the file\n",
        "#with open(\"path_to_summaries.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        " #   all_summaries = file.readlines()\n",
        "\n",
        "# Expanded list of uncertainty-inflicting words\n",
        "#uncertain_words = []\n",
        "\n",
        "# Filter out summaries that contain uncertain words\n",
        "definitive_summaries = [summary for summary in summaries if not any(word in summary.lower() for word in uncertain_words)]\n",
        "\n",
        "# Split the definitive summaries into training and validation sets\n",
        "train_summaries, eval_summaries = train_test_split(definitive_summaries, test_size=0.1, random_state=42)\n",
        "\n",
        "# Tokenize the data\n",
        "def tokenize_data(summaries, tokenizer):\n",
        "    inputs = tokenizer(summaries, truncation=True, padding='max_length', max_length=1024, return_tensors='pt')\n",
        "    targets = tokenizer(summaries, truncation=True, padding='max_length', max_length=150, return_tensors='pt')\n",
        "    return inputs, targets\n",
        "\n",
        "train_inputs, train_targets = tokenize_data(train_summaries, tokenizer)\n",
        "eval_inputs, eval_targets = tokenize_data(eval_summaries, tokenizer)\n",
        "\n",
        "# Create a custom dataset\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, inputs, targets):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_data = {key: val[idx] for key, val in self.inputs.items()}\n",
        "        target_data = {key: val[idx] for key, val in self.targets.items()}\n",
        "        return {\"input_ids\": input_data[\"input_ids\"], \"attention_mask\": input_data[\"attention_mask\"], \"labels\": target_data[\"input_ids\"]}\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=2,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    save_steps=100,\n",
        "    save_total_limit=2,\n",
        "    evaluation_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "# Load YOUR trained BART model\n",
        "model_path = \"C:\\\\Users\\\\modza\\\\Downloads\\\\BART_CustomSummarization\"  # Replace with your model directory path\n",
        "model = BartForConditionalGeneration.from_pretrained(model_path)\n",
        "\n",
        "# Create datasets for training and evaluation\n",
        "train_dataset = CustomDataset(train_inputs, train_targets)\n",
        "eval_dataset = CustomDataset(eval_inputs, eval_targets)\n",
        "\n",
        "# Initialize the trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset\n",
        ")\n",
        "\n",
        "# Start fine-tuning\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "i648PU_QJSw7",
        "outputId": "2d4eb9df-617d-4126-fcbb-802b5270ed93"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='138' max='138' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [138/138 1:16:41, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.029300</td>\n",
              "      <td>0.033675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.008100</td>\n",
              "      <td>0.027047</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=138, training_loss=0.06518451721016047, metrics={'train_runtime': 4633.7454, 'train_samples_per_second': 0.119, 'train_steps_per_second': 0.03, 'total_flos': 1191907531161600.0, 'train_loss': 0.06518451721016047, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.save_pretrained(\"C:\\\\Users\\\\modza\\\\Downloads\\\\BART_Retrained\")\n",
        "tokenizer.save_pretrained(\"C:\\\\Users\\\\modza\\\\Downloads\\\\BART_Retrained\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqImpRGfgmb2",
        "outputId": "9ec1b45a-06a5-4bec-da7e-777159846283"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('C:\\\\Users\\\\modza\\\\Downloads\\\\BART_Retrained/tokenizer_config.json',\n",
              " 'C:\\\\Users\\\\modza\\\\Downloads\\\\BART_Retrained/special_tokens_map.json',\n",
              " 'C:\\\\Users\\\\modza\\\\Downloads\\\\BART_Retrained/vocab.json',\n",
              " 'C:\\\\Users\\\\modza\\\\Downloads\\\\BART_Retrained/merges.txt',\n",
              " 'C:\\\\Users\\\\modza\\\\Downloads\\\\BART_Retrained/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "def extract_benefits_from_summary(article):\n",
        "    # Load pre-trained BART model for summarization\n",
        "    model = BartForConditionalGeneration.from_pretrained(\"C:\\\\Users\\\\modza\\\\Downloads\\\\BART_Retrained\")\n",
        "    tokenizer = BartTokenizer.from_pretrained(\"C:\\\\Users\\\\modza\\\\Downloads\\\\BART_Retrained\")\n",
        "\n",
        "\n",
        "    # Generate summary\n",
        "    inputs = tokenizer([article], max_length=1024, return_tensors='pt', truncation=True)\n",
        "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=50, max_length=300, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Define keywords or phrases that might indicate benefits\n",
        "    benefit_keywords = ['benefit', 'advantage', 'gain', 'merit','prevention','Treatment','cure','reward', 'bonus', 'profit', 'value', 'asset', 'boon', 'perk', 'upside', 'plus', 'positive', 'improvement', 'enhancement', 'dividend', 'utility', 'favor', 'help', 'aid', 'good', 'pro']\n",
        "\n",
        "    # Extract sentences containing benefits\n",
        "    benefits_sentences = [sentence for sentence in summary.split('. ') if any(keyword in sentence.lower() for keyword in benefit_keywords)]\n",
        "\n",
        "    # Combine the extracted sentences into bullet points\n",
        "    benefits_summary = '\\n'.join([f'- {sentence}' for sentence in benefits_sentences])\n",
        "\n",
        "    return benefits_summary\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6ROeUDgFhpUO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "# Filter out sections for which summaries contain uncertain words\n",
        "filtered_sections = [sections[i] for i, summary in enumerate(summaries) if not any(word in summary.lower() for word in uncertain_words)]\n",
        "filtered_summaries = [summary for summary in summaries if not any(word in summary.lower() for word in uncertain_words)]\n",
        "\n",
        "# Split the filtered data into training and validation sets\n",
        "train_sections, eval_sections, train_summaries, eval_summaries = train_test_split(filtered_sections, filtered_summaries, test_size=0.1, random_state=42)\n",
        "\n",
        "# Tokenize the data\n",
        "def tokenize_data(sections, summaries, tokenizer):\n",
        "    inputs = tokenizer(sections, truncation=True, padding='max_length', max_length=1024, return_tensors='pt')\n",
        "    targets = tokenizer(summaries, truncation=True, padding='max_length', max_length=150, return_tensors='pt')\n",
        "    return inputs, targets\n",
        "\n",
        "train_inputs, train_targets = tokenize_data(train_sections, train_summaries, tokenizer)\n",
        "eval_inputs, eval_targets = tokenize_data(eval_sections, eval_summaries, tokenizer)\n",
        "\n",
        "# Create a custom dataset\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, inputs, targets):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_data = {key: val[idx] for key, val in self.inputs.items()}\n",
        "        target_data = {key: val[idx] for key, val in self.targets.items()}\n",
        "        return {\"input_ids\": input_data[\"input_ids\"], \"attention_mask\": input_data[\"attention_mask\"], \"labels\": target_data[\"input_ids\"]}\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=2,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    save_steps=100,\n",
        "    save_total_limit=2,\n",
        "    evaluation_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "# Load the pre-trained BART model\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "# Create datasets for training and evaluation\n",
        "train_dataset = CustomDataset(train_inputs, train_targets)\n",
        "eval_dataset = CustomDataset(eval_inputs, eval_targets)\n",
        "\n",
        "# Initialize the trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset\n",
        ")\n",
        "\n",
        "# Start fine-tuning\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "twNOVeGbfyTm",
        "outputId": "9d26878a-c20c-4e74-944d-d67a26f73b79"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='138' max='138' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [138/138 04:49, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.060600</td>\n",
              "      <td>0.853079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.654600</td>\n",
              "      <td>0.810569</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=138, training_loss=1.476087566735088, metrics={'train_runtime': 291.5983, 'train_samples_per_second': 1.886, 'train_steps_per_second': 0.473, 'total_flos': 1191907531161600.0, 'train_loss': 1.476087566735088, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "def extract_benefits_from_summary(article):\n",
        "    # Load pre-trained BART model for summarization\n",
        "    model = BartForConditionalGeneration.from_pretrained(\"C:\\\\Users\\\\modza\\\\Downloads\\\\BART_Retrained\")\n",
        "    tokenizer = BartTokenizer.from_pretrained(\"C:\\\\Users\\\\modza\\\\Downloads\\\\BART_Retrained\")\n",
        "\n",
        "\n",
        "    # Generate summary\n",
        "    inputs = tokenizer([article], max_length=1024, return_tensors='pt', truncation=True)\n",
        "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=50, max_length=300, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Define keywords or phrases that might indicate benefits\n",
        "    benefit_keywords = ['benefit', 'advantage', 'gain', 'merit','prevention','Treatment','cure','reward', 'bonus', 'profit', 'value', 'asset', 'boon', 'perk', 'upside', 'plus', 'positive', 'improvement', 'enhancement', 'dividend', 'utility', 'favor', 'help', 'aid', 'good', 'pro']\n",
        "\n",
        "    # Extract sentences containing benefits\n",
        "    benefits_sentences = [sentence for sentence in summary.split('. ') if any(keyword in sentence.lower() for keyword in benefit_keywords)]\n",
        "\n",
        "    # Combine the extracted sentences into bullet points\n",
        "    benefits_summary = '\\n'.join([f'- {sentence}' for sentence in benefits_sentences])\n",
        "\n",
        "    return benefits_summary"
      ],
      "metadata": {
        "id": "9hl9F4JQhKcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article1 = \"Chia seeds are a great source of fiber, which can improve heart health, reduce cholesterol levels, and promote intestinal health.1 They also contain quercetin, an antioxidant that can reduce the risk of heart disease.0 Chia seeds are high in omega-3 fatty acids, which have anti-inflammatory and heart health properties.5 They also contain minerals such as calcium, magnesium, and phosphorus, which are beneficial for bone health.2 Additionally, chia seeds provide numerous B-vitamins, including thiamin, riboflavin, and niacin, which play important roles in metabolism and cardiovascular health.3 Recent research has found that chia seeds can help promote healthy skin, reduce signs of aging, support the digestive system, and build stronger bones\""
      ],
      "metadata": {
        "id": "rlPznuhdoKKO"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_benefits_from_summary(article, model, tokenizer):\n",
        "    # Ensure the model is on the GPU\n",
        "    model = model.to('cuda')\n",
        "\n",
        "    # Tokenize the article\n",
        "    inputs = tokenizer([article], max_length=1024, return_tensors='pt', truncation=True)\n",
        "\n",
        "    # Move the inputs to the GPU\n",
        "    inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=50, max_length=300, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Define keywords or phrases that might indicate benefits\n",
        "    benefit_keywords = ['benefit', 'advantage', 'gain', 'merit', 'prevention', 'treatment', 'cure', 'reward', 'bonus', 'profit', 'value', 'asset', 'boon', 'perk', 'upside', 'plus', 'positive', 'improvement', 'enhancement', 'dividend', 'utility', 'favor', 'help', 'aid', 'good', 'pro']\n",
        "\n",
        "    # Extract sentences containing benefits\n",
        "    benefits_sentences = [sentence for sentence in summary.split('. ') if any(keyword in sentence.lower() for keyword in benefit_keywords)]\n",
        "\n",
        "    # Combine the extracted sentences into bullet points\n",
        "    benefits_summary = '\\n'.join([f'- {sentence}' for sentence in benefits_sentences])\n",
        "\n",
        "    return benefits_summary\n"
      ],
      "metadata": {
        "id": "JTQta1ExpJJZ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article2 = \"\"\" Chrissy Freer, taste.com.au Nutrition Editor, told us that chia seeds are loaded with fibre (especially soluble fibre with cholesterol-lowering properties) and just 2 tbs of chia will add almost 10g dietary fibre to your diet.\n",
        "\n",
        "“Chia seeds are a great way to boost your daily fibre intake and this is essential for optimal gut health and related to the reduced number of chronic diseases including type 2 diabetes, heart disease and certain cancers,” says Freer.\n",
        "\n",
        "Chia seeds are also a good source of plant protein and the winning combo of protein and fibre gives you that feeling of fullness which makes them a great addition to a healthy weight management plan.\n",
        "\n",
        "Chia seeds are also a valuable source of several minerals including calcium for healthy bones, magnesium which can help ease the symptoms of premenstrual syndrome including water retention, migraine headaches and cramps.\n",
        "\n",
        "And if all that wasn’t enough, chia also contains beneficial antioxidants which may be protective against several disease including heart disease and certain cancers. We told you those seeds were small but mighty!\"\"\""
      ],
      "metadata": {
        "id": "J3MJj_AApzSn"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benefits_extracted = extract_benefits_from_summary(article2, model, tokenizer)\n",
        "print(benefits_extracted)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W-7Ln-fpbeR",
        "outputId": "5ae9a30c-d486-422a-b52a-d276cce3d5b0"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Superfoods are high in fiber, protein, fiber, vitamins, minerals, antioxidants, vitamins and minerals\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ktbQXSwpcbz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b65047c9f68f45fc9ea91c9dea68d490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2717392febe427bbf1880a9d2badbd4",
              "IPY_MODEL_41eb481a6cd448c89e04a2d9f0b3be4b",
              "IPY_MODEL_81090e04fa544b08b3ed5dfbdd541262"
            ],
            "layout": "IPY_MODEL_5c311aa643da47138f75756f10517a66"
          }
        },
        "b2717392febe427bbf1880a9d2badbd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0861831f8f74515800d7f689634ec53",
            "placeholder": "​",
            "style": "IPY_MODEL_1d854f248fa04b8cae9ed2456a865820",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "41eb481a6cd448c89e04a2d9f0b3be4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df04483e138c4897a454e32739ee7e75",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6590f696a34b43ebad6dec4c825a6407",
            "value": 898823
          }
        },
        "81090e04fa544b08b3ed5dfbdd541262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_190373a948fe4dd189add2595c43df8e",
            "placeholder": "​",
            "style": "IPY_MODEL_8a2e353ad1aa44f493a7e362994723a1",
            "value": " 899k/899k [00:00&lt;00:00, 16.5MB/s]"
          }
        },
        "5c311aa643da47138f75756f10517a66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0861831f8f74515800d7f689634ec53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d854f248fa04b8cae9ed2456a865820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df04483e138c4897a454e32739ee7e75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6590f696a34b43ebad6dec4c825a6407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "190373a948fe4dd189add2595c43df8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a2e353ad1aa44f493a7e362994723a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38434f784ef44a939a9083b326a57286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e73eb7bb7ef241dc8d1a5f3d1bdb4c49",
              "IPY_MODEL_77def51c336d42149bd3620887a98ea1",
              "IPY_MODEL_f3875c84581744cfb2999906e20a5636"
            ],
            "layout": "IPY_MODEL_55b16c02d9684446b7620e02785c6c64"
          }
        },
        "e73eb7bb7ef241dc8d1a5f3d1bdb4c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42a82287037240c0b9120e4e8e0812ae",
            "placeholder": "​",
            "style": "IPY_MODEL_6686e9ac68064caa9176408259a6ccc0",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "77def51c336d42149bd3620887a98ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c794f2d5bf524ecf9ab67aecf692a691",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_494bc067beca4b2082d61e5fdd970f71",
            "value": 456318
          }
        },
        "f3875c84581744cfb2999906e20a5636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c815a646dcc4b519cf267ee21418152",
            "placeholder": "​",
            "style": "IPY_MODEL_3245a303502546cfa6890fd7c52b2a8f",
            "value": " 456k/456k [00:00&lt;00:00, 34.6MB/s]"
          }
        },
        "55b16c02d9684446b7620e02785c6c64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42a82287037240c0b9120e4e8e0812ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6686e9ac68064caa9176408259a6ccc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c794f2d5bf524ecf9ab67aecf692a691": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "494bc067beca4b2082d61e5fdd970f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c815a646dcc4b519cf267ee21418152": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3245a303502546cfa6890fd7c52b2a8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c68df0f2e294b62a9edc555132bc948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48fffd306355434bbafe681ca447d0ae",
              "IPY_MODEL_f39c2a613d2f4cd8a0e18fe052b02f98",
              "IPY_MODEL_541e558654df4097bf71119302bc03c0"
            ],
            "layout": "IPY_MODEL_4728e2264a3d4f93b143dbead7285216"
          }
        },
        "48fffd306355434bbafe681ca447d0ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc611585e8d644fc89055b92ccfdc9d6",
            "placeholder": "​",
            "style": "IPY_MODEL_3b6236b2330e442db5f3187d37f2ab22",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "f39c2a613d2f4cd8a0e18fe052b02f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_842345bd8721411cbf4ebb4cafd3c8e9",
            "max": 1585,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7266f48f1944df08243c2b76742aa26",
            "value": 1585
          }
        },
        "541e558654df4097bf71119302bc03c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24d3edd92b794424bb4d15646668fdf0",
            "placeholder": "​",
            "style": "IPY_MODEL_9f1ca9eae8ca44828d2e7540b907400c",
            "value": " 1.58k/1.58k [00:00&lt;00:00, 162kB/s]"
          }
        },
        "4728e2264a3d4f93b143dbead7285216": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc611585e8d644fc89055b92ccfdc9d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b6236b2330e442db5f3187d37f2ab22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "842345bd8721411cbf4ebb4cafd3c8e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7266f48f1944df08243c2b76742aa26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24d3edd92b794424bb4d15646668fdf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f1ca9eae8ca44828d2e7540b907400c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6370fde738b4596b3d437ee6e65104f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_981ede54163e4f68a24d9a8724e7e2fd",
              "IPY_MODEL_3ae658b56c654d70be2252cf8d23da17",
              "IPY_MODEL_61f60d5d50ed4778a79dad870bee629f"
            ],
            "layout": "IPY_MODEL_f5ccb072631c476d84aab5229f1969bd"
          }
        },
        "981ede54163e4f68a24d9a8724e7e2fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6c0566ac5f749d59eb6d5ef10d303a1",
            "placeholder": "​",
            "style": "IPY_MODEL_16382b23b4814b868973f683392db3da",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "3ae658b56c654d70be2252cf8d23da17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f79be3b745174644b480d99a816961b1",
            "max": 1625270765,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb91ed0fbdbf4ba18108e60fd77f1365",
            "value": 1625270765
          }
        },
        "61f60d5d50ed4778a79dad870bee629f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46c87a3e2ea446f8bffa56e6d7de723e",
            "placeholder": "​",
            "style": "IPY_MODEL_977733955da547e8b576e1b3de5a94ef",
            "value": " 1.63G/1.63G [00:04&lt;00:00, 349MB/s]"
          }
        },
        "f5ccb072631c476d84aab5229f1969bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6c0566ac5f749d59eb6d5ef10d303a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16382b23b4814b868973f683392db3da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f79be3b745174644b480d99a816961b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb91ed0fbdbf4ba18108e60fd77f1365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46c87a3e2ea446f8bffa56e6d7de723e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "977733955da547e8b576e1b3de5a94ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8c0edb5e720462c83460f696721753f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03e3df919dc14ecda67b078a5a59eaa2",
              "IPY_MODEL_dacd70cfe5ca402baade375f8029b192",
              "IPY_MODEL_8c408cc2b35b49ebaf619b97d9d7193c"
            ],
            "layout": "IPY_MODEL_db26e957c7d84408bf0f00d3cb25aa9d"
          }
        },
        "03e3df919dc14ecda67b078a5a59eaa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ce916e72f2645e5825d8b91eab7704d",
            "placeholder": "​",
            "style": "IPY_MODEL_504f7a4390b84ff4a242cb42408ba7fd",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "dacd70cfe5ca402baade375f8029b192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5c55170e3fd4dfea25eea31bd307176",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39f1fa54bac145619d802f37c40547c9",
            "value": 363
          }
        },
        "8c408cc2b35b49ebaf619b97d9d7193c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_493ea7e5494a40ab87a203f6db40fed4",
            "placeholder": "​",
            "style": "IPY_MODEL_cfe47271d1e94d4fbca9ca733dd4e1b7",
            "value": " 363/363 [00:00&lt;00:00, 31.1kB/s]"
          }
        },
        "db26e957c7d84408bf0f00d3cb25aa9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ce916e72f2645e5825d8b91eab7704d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "504f7a4390b84ff4a242cb42408ba7fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5c55170e3fd4dfea25eea31bd307176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39f1fa54bac145619d802f37c40547c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "493ea7e5494a40ab87a203f6db40fed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfe47271d1e94d4fbca9ca733dd4e1b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}